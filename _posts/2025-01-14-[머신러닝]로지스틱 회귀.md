---
title:  "[머신러닝]로지스틱 회귀"
categories:
  - ML
---  
# 로지스틱 회귀를 하기 전 기본 개념
- 확률을 사용하여 이진분류를 수행하는 방법
- 회귀이지만 분류할 때 사용된다.
- 로지스틱 회귀를 배우기 전 오즈, 로짓, 로지스틱 회귀 방정식, 시그모이드 함수 등을 알아야한다.

## 오즈(Odds)
- 일어날 확률과 일어나지 않을 확률의 비
- 승산이라고도 말한다.
![1750b2e9-d9ba-4226-bea4-2ad69abd5040](https://github.com/user-attachments/assets/d938035b-35fd-4160-9915-4779e7a4c378)

## 로짓(Logit)
- 오즈의 값에는 범위의 제한이 있기에 로그를 취해 범위의 제한을 없앤다.
![19a2647a-7343-478d-b97a-432b6bdc117a](https://github.com/user-attachments/assets/efb56f2e-5990-4adb-80ac-b8ba6d8281c6)
![8d7d9ebb-c4a5-4fd6-b2d2-d8f863dea7e7](https://github.com/user-attachments/assets/9c874587-ec2d-4411-b0e3-cc0435e08fd6)

## 로지스틱 회귀 방정식(Logistic Regression Model)
- 로짓을 통해 로지스틱 회귀 방정식을 얻을 수 있다.
![4aacfd76-fad3-4c5a-81ae-54b527a11c48](https://github.com/user-attachments/assets/b74f222e-559e-4a84-b848-1a9180bf0651)

## 시그모이드 함수(Sigmoid Function)
- 로지스틱 회귀 방정식과 유사한 함수이다.
![f8708a51-de07-40d7-9c7c-43824f4928cf](https://github.com/user-attachments/assets/1d1a1ccd-607d-42b5-9351-5df1ce098b33)

# 로지스틱 회귀의 과정
- 로지스틱 회귀은 어떠한 과정으로 이루어지는지 알아본다.

## 1. 예측함수 정의
- 다른 모델과 마찬가지로 일단 예측함수부터 정의된다.
- 예측함수는 위 개념 중 로지스틱 회귀 방정식으로 정의된다.
![72227de0-a760-40c8-9001-4a235a2a10b5](https://github.com/user-attachments/assets/92f20044-9561-482f-a426-fd859d17372c)

## 2. 비용함수 정의
- 로지스틱 회귀의 비용함수는 다른 모델처럼 정의되지 않는다.
- 다른 모델처럼 정의할 시 Convex한 함수가 아니기 때문이다.
- 그러므로 비용함수를 다음과 같이 정의한다.
![ac6eb6c7-2725-467d-af23-416db2d3379f](https://github.com/user-attachments/assets/12c79aeb-6170-449d-8eb8-0c7a9cb71526)

## 3. 파라미터(w) 결정
- 예측함수와 비용함수를 정의했다면 다음은 파라미터를 결정해야한다.
- 로지스틱 회귀에서는 최대우도추정법으로 파라미터를 결정할 수 있다.
![7c9287f9-10f7-4577-ba4e-88c4996a901b](https://github.com/user-attachments/assets/c280c151-2410-4363-b5b5-7abc4f6c25d2)
![cc465bdb-9e5b-4193-869b-f20c56b77b2c](https://github.com/user-attachments/assets/96c6789f-613d-4e59-b817-4ebf6cceafea)

## 4. 평가
- 로지스틱 회귀의 평가지표에는 정확도, 정밀도 등 여러가지가 있다.
- TP (True Positive): 실제 값이 1이고, 모델이 1로 예측한 경우
- TN (True Negative): 실제 값이 0이고, 모델이 0으로 예측한 경우
- FP (False Positive): 실제 값이 0인데, 모델이 1로 예측한 경우
- FN (False Negative): 실제 값이 1인데, 모델이 0으로 예측한 경우

### 정확도(Accuracy)
- 모델이 올바르게 예측한 비율
![6818b294-4c04-4e00-b8d0-e6c9afe1388c](https://github.com/user-attachments/assets/42f59a64-2575-4c13-bfc7-7c8b8de98b01)

### 정밀도(Precision)
- 모델이 1로 예측한 것 중 실제로 1인 비율
![692e7be8-0ee9-4d1c-86e5-45ac5d891e93](https://github.com/user-attachments/assets/7d62eb47-75b6-408a-b443-32524ba89b2d)

### 재현율(Recall)
- 실제 1인 데이터 중 모델이 1로 올바르게 예측한 비율
![e2e02307-fab3-4fae-b2a1-ac9b64b6a824](https://github.com/user-attachments/assets/b7ca1676-6803-4246-95ba-4b66b4214478)

### F1-스코어(F1-Score)
- 정밀도와 재현율의 조화평균
![b9b3964b-6ba7-4ecc-84e5-83f2dc42dcc9](https://github.com/user-attachments/assets/eb5269bf-2dd4-4264-adc1-fff4b440c6a4)

### 로그손실(Logloss)
- 로지스틱 회귀의 확률 예측 값에 기반한 손실 함수
![32be0802-a481-4513-9527-264acb960ab8](https://github.com/user-attachments/assets/ade50e0b-4ec7-4941-b2a4-f9ebef945d93)

# 로지스틱 회귀의 예제


```python
# 라이브러리 드드
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
```


```python
# 데이터 생성
np.random.seed(42)
study_hours = np.random.uniform(0, 10, 100) 
pass_exam = (study_hours + np.random.normal(0, 1, 100) > 5).astype(int)
data = pd.DataFrame({'Study Hours': study_hours, 'Pass Exam': pass_exam})
```


```python
# 데이터 시각화
plt.scatter(data['Study Hours'], data['Pass Exam'], c=data['Pass Exam'], cmap='bwr', edgecolor='k')
plt.xlabel('Study Hours')
plt.ylabel('Pass Exam (0: Fail, 1: Pass)')
plt.title('Study Hours vs Exam Result')
plt.show()
```


    
![output_18_0](https://github.com/user-attachments/assets/6dbff209-5a90-4a7c-907d-7cea20cf63c4)
    



```python
# 피처 데이터와 타겟 데이터 분리
X = data[['Study Hours']]  
y = data['Pass Exam']      

# 학습용/테스트용 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 로지스틱 회귀 모델 생성 및 학습
model = LogisticRegression()
model.fit(X_train, y_train)

# 학습된 모델로 예측
y_pred = model.predict(X_test)

# 정확도 평가
print("Accuracy:", accuracy_score(y_test, y_pred))
```

    Accuracy: 1.0
    


```python
x_values = np.linspace(0, 10, 100).reshape(-1, 1)  # 0~10 사이의 값
y_prob = model.predict_proba(x_values)[:, 1]       # 통과 확률 (클래스 1)

plt.scatter(data['Study Hours'], data['Pass Exam'], c=data['Pass Exam'], cmap='bwr', edgecolor='k', label='Data')
plt.plot(x_values, y_prob, color='black', label='Logistic Regression Curve')
plt.xlabel('Study Hours')
plt.ylabel('Pass Probability')
plt.title('Logistic Regression: Study Hours vs Pass Probability')
plt.legend()
plt.show()
```

    C:\Users\mose7\anaconda3\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
      warnings.warn(
    


    
![output_20_1](https://github.com/user-attachments/assets/441652d3-a531-49ee-a8de-8b63a73d2e1b)
    

