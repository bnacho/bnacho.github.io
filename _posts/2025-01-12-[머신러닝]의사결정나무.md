---
title:  "[머신러닝]의사결정나무"
categories:
  - ML
---  
# 의사결정나무란?
- 스무고개과 비슷하다고 생각할 수 있다.
- 분류와 회귀를 진행할 수 있다.
- 데이터를 정보 엔트로피, 지니 지수 등을 사용하여 정보이득을 계산한 후 정보이득이 큰 피처로 분할한다.
- 계속 분할하여 분류 혹은 회귀를 수행한다.

## 정보 엔트로피와 지니 지수
- 어떠한 데이터에 불순도, 무질서도를 측정하는 개념이다.
- 이를 통해 데이터의 분할 기준을 정한다.
![1b497110-6d3e-46df-808a-48a8361cc93b](https://github.com/user-attachments/assets/ce1c7e59-ba8e-49f4-a6db-313c614bd724)

## 정보이득
- 데이터 집합을 부분집합으로 분할하여 얻을 수 있는 정보량이다.
- 분할 가능한 피처의 정보이득을 계산하여 정보 이득이 큰 피처로 데이터를 분할한다.
![0f1fcaf6-1260-41eb-85ee-d93507ecabf6](https://github.com/user-attachments/assets/ca07f288-4345-4e52-a238-54e691d27b6a)

## 데이터의 분할
- 나무 모양으로 데이터를 분할하며 노드와 가지로 구성되어 있다.
- 노드는 입력에 대한 질문 역할을 하며 가지는 그에 대한 답 역할을 한다.
- 노드 중에서 제일 위에 있는 노드를 뿌리노드, 마지막에 최종 출력을 담당하는 단말노드, 나머지는 중간노드라고 한다.
- 
![5d0db83b-3acc-42bd-8835-1a7bc26b31fe](https://github.com/user-attachments/assets/30c3bd83-5fa2-45f6-b0bd-e63103b479e8)

# 의사결정나무로 분류하기
- 데이터를 정보 엔트로피, 지니 지수 등을 사용하여 정보이득을 계산한다.
- 정보이득이 큰 피처로 데이터를 나눠나간다.
- 최종노드에는 클래스를 들어간다.


```python
from sklearn.tree import DecisionTreeClassifier # 의사결정나무 불러오기
from sklearn.datasets import load_iris # 사용할 데이터셋 불러오기
from sklearn.model_selection import train_test_split # 학습데이터, 테스트데이터 분할
from sklearn.metrics import accuracy_score # 정확도 측정
```


```python
# 데이터 불러오기
data = load_iris()

# 데이터를 feature와 target으로 분리
X = data.data
y = data.target

# 학습데이터, 테스트 데이터 분리(test_size : 학습데이터와 테스트데이터의 비율, random_state : 결과의 재현성을 위해 시드 고정
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

# 모델 생성 및 학습
model = DecisionTreeClassifier(random_state = 42)
model.fit(X_train, y_train)

# 예측 및 정확도 측정
y_pred = model.predict(X_test)
print("정확도", accuracy_score(y_test, y_pred))
```

    정확도 1.0
    

# 의사결정나무로 회귀하기
- 분류와 비슷하지만 최종노드에는 예측치가 들어간다.


```python
from sklearn.tree import DecisionTreeRegressor # 의사결정나무 불러오기
from sklearn.datasets import make_regression # 회귀 데이터를 만들기 위한 라이브러리
from sklearn.model_selection import train_test_split # 학습데이터, 테스트데이터 분할
from sklearn.metrics import mean_squared_error # 정확도 측정
```


```python
# 데이터 생성
X, y = make_regression(n_samples=100, n_features=4, noise=0.1, random_state=42)

# 학습데이터, 테스트 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 모델 생성 및 학습
model = DecisionTreeRegressor(random_state=42)
model.fit(X_train, y_train)

# 예측 및 정확도 측정
y_pred = model.predict(X_test)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
```

    Mean Squared Error: 2486.757141010369
    

# 의사결정나무의 주요 파라미터
- max_depth : 트리의 최대 깊이를 제한 => 과적합 방지 가능
- min_samples_split: 노드를 분할하기 위한 최소 샘플 수
- min_samples_leaf: 리프 노드에 있어야 하는 최소 샘플 수
- criterion : 분류는 gini 혹은 entropy, 회귀는 squared_mse 혹은 friedman_mse를 사용
- random_state : 결과의 재현성을 위해 시드 고정
